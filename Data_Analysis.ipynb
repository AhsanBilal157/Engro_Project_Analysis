{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "842df501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30878, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time of Report: 3/16/2025 16:22:34</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Requester: CSTN01-1 - Oper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filter Applied: Event Time: Live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sort Criteria:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Server: ESV-01B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tip: to see the full time in Excel, use a cust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30873</th>\n",
       "      <td>3/14/2025 9:37:10.800</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2289579af-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30874</th>\n",
       "      <td>3/14/2025 9:37:10.700</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2289579af-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M3/H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30875</th>\n",
       "      <td>3/14/2025 9:37:10.600</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2289579af-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30876</th>\n",
       "      <td>3/14/2025 9:37:10.600</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2289579af-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M3/H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30877</th>\n",
       "      <td>3/14/2025 9:37:10.500</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2289579af-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30878 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date/Time of Report: 3/16/2025 16:22:34 Unnamed: 1  \\\n",
       "0                             Requester: CSTN01-1 - Oper        NaN   \n",
       "1                       Filter Applied: Event Time: Live        NaN   \n",
       "2                                        Sort Criteria:         NaN   \n",
       "3                                        Server: ESV-01B        NaN   \n",
       "4      Tip: to see the full time in Excel, use a cust...        NaN   \n",
       "...                                                  ...        ...   \n",
       "30873                              3/14/2025 9:37:10.800         01   \n",
       "30874                              3/14/2025 9:37:10.700         01   \n",
       "30875                              3/14/2025 9:37:10.600         01   \n",
       "30876                              3/14/2025 9:37:10.600         01   \n",
       "30877                              3/14/2025 9:37:10.500         01   \n",
       "\n",
       "                       Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
       "0                             NaN        NaN        NaN        NaN   \n",
       "1                             NaN        NaN        NaN        NaN   \n",
       "2                             NaN        NaN        NaN        NaN   \n",
       "3                             NaN        NaN        NaN        NaN   \n",
       "4                             NaN        NaN        NaN        NaN   \n",
       "...                           ...        ...        ...        ...   \n",
       "30873  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "30874  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "30875  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "30876  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "30877  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "\n",
       "                        Unnamed: 6 Unnamed: 7 Unnamed: 8  Unnamed: 9  \n",
       "0                              NaN        NaN        NaN         NaN  \n",
       "1                              NaN        NaN        NaN         NaN  \n",
       "2                              NaN        NaN        NaN         NaN  \n",
       "3                              NaN        NaN        NaN         NaN  \n",
       "4                              NaN        NaN        NaN         NaN  \n",
       "...                            ...        ...        ...         ...  \n",
       "30873  DATA;$330013f2289579af-0006        NaN        MIN         NaN  \n",
       "30874  DATA;$330013f2289579af-0006        NaN       M3/H         NaN  \n",
       "30875  DATA;$330013f2289579af-0006        NaN        MIN         NaN  \n",
       "30876  DATA;$330013f2289579af-0006        NaN       M3/H         NaN  \n",
       "30877  DATA;$330013f2289579af-0006        NaN        MIN         NaN  \n",
       "\n",
       "[30878 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./PVC-I (Jan, Feb, Mar) EVENTS/21jan.csv\", on_bad_lines='skip')\n",
    "print(data.shape)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3eca920-4314-4661-ba2d-5711ba311bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time of Report: 3/16/2025 16:22:34</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Event Time</td>\n",
       "      <td>Location Tag</td>\n",
       "      <td>Source</td>\n",
       "      <td>Condition</td>\n",
       "      <td>Action</td>\n",
       "      <td>Priority</td>\n",
       "      <td>Description</td>\n",
       "      <td>Value</td>\n",
       "      <td>Units</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/16/2025 16:22:34.587</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3/16/2025 16:22:14.211</td>\n",
       "      <td>1500</td>\n",
       "      <td>FQC1504</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.mode</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3/16/2025 16:22:13.185</td>\n",
       "      <td>1500</td>\n",
       "      <td>FQC1504</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.sp</td>\n",
       "      <td>0</td>\n",
       "      <td>kg/h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3/16/2025 16:22:11.318</td>\n",
       "      <td>1500</td>\n",
       "      <td>FQC1504</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.mode</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3/16/2025 16:17:50.100</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f229de7ede-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3/16/2025 16:17:50.100</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f229de7ede-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3/16/2025 16:17:50.000</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f229de7ede-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3/16/2025 16:17:50.000</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f229de7ede-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3/16/2025 16:17:50.000</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f229de7ede-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date/Time of Report: 3/16/2025 16:22:34    Unnamed: 1  \\\n",
       "7                               Event Time  Location Tag   \n",
       "8                   3/16/2025 16:22:34.587    SERVER_PVC   \n",
       "9                   3/16/2025 16:22:14.211          1500   \n",
       "10                  3/16/2025 16:22:13.185          1500   \n",
       "11                  3/16/2025 16:22:11.318          1500   \n",
       "..                                     ...           ...   \n",
       "95                  3/16/2025 16:17:50.100            01   \n",
       "96                  3/16/2025 16:17:50.100            01   \n",
       "97                  3/16/2025 16:17:50.000            01   \n",
       "98                  3/16/2025 16:17:50.000            01   \n",
       "99                  3/16/2025 16:17:50.000            01   \n",
       "\n",
       "                    Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
       "7                       Source  Condition     Action   Priority   \n",
       "8                          NaN     Demand        NaN        NaN   \n",
       "9                      FQC1504     CHANGE        NaN        NaN   \n",
       "10                     FQC1504     CHANGE        NaN        NaN   \n",
       "11                     FQC1504     CHANGE        NaN        NaN   \n",
       "..                         ...        ...        ...        ...   \n",
       "95  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "96  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "97  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "98  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "99  $ACTIVITY_330413F2352AB609    Formula        NaN       J 00   \n",
       "\n",
       "                     Unnamed: 6 Unnamed: 7 Unnamed: 8  Unnamed: 9  \n",
       "7                   Description      Value      Units         NaN  \n",
       "8     CSV export in progress...        NaN        NaN         NaN  \n",
       "9                     pida.mode     NORMAL        NaN         NaN  \n",
       "10                      pida.sp          0       kg/h         NaN  \n",
       "11                    pida.mode       AUTO        NaN         NaN  \n",
       "..                          ...        ...        ...         ...  \n",
       "95  DATA;$330013f229de7ede-0006        NaN        MIN         NaN  \n",
       "96  DATA;$330013f229de7ede-0006        NaN          %         NaN  \n",
       "97  DATA;$330013f229de7ede-0006        NaN        NaN         NaN  \n",
       "98  DATA;$330013f229de7ede-0006        NaN        MIN         NaN  \n",
       "99  DATA;$330013f229de7ede-0006        NaN        MIN         NaN  \n",
       "\n",
       "[93 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7074a-61b3-4636-9af8-017dba74efcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf5b9a60-2c08-4280-947a-a1728237c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Unnamed: 0    Unnamed: 1 Unnamed: 2  \\\n",
      "0             Event Time  Location Tag     Source   \n",
      "1  2/1/2025 23:59:13.104          8800    PIC8808   \n",
      "2  2/1/2025 23:58:40.313          8800    PIC8808   \n",
      "3  2/1/2025 23:58:26.196          8800    PIC8808   \n",
      "4  2/1/2025 23:58:23.521          8800    PIC8808   \n",
      "5  2/1/2025 23:57:55.465    IOLINK01_1   AIOR-103   \n",
      "6  2/1/2025 23:57:42.150          8800     TI8808   \n",
      "7  2/1/2025 23:57:42.150          8800     TI8808   \n",
      "8  2/1/2025 23:57:38.385          8100    AI_PH10   \n",
      "9  2/1/2025 23:56:54.100          8100    AI_PH10   \n",
      "\n",
      "                      Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
      "0                      Condition     Action   Priority   \n",
      "1                         CHANGE        NaN        NaN   \n",
      "2                         CHANGE        NaN        NaN   \n",
      "3                         CHANGE        NaN        NaN   \n",
      "4                         CHANGE        NaN        NaN   \n",
      "5  OP Fail in circuit/field wire        ACK        NaN   \n",
      "6                          ALARM    ACK PNT        NaN   \n",
      "7                          PVLOW        ACK        NaN   \n",
      "8                         PVHIHI        ACK        NaN   \n",
      "9                         PVHIHI        NaN       H 00   \n",
      "\n",
      "                 Unnamed: 6 Unnamed: 7 Unnamed: 8  \n",
      "0               Description      Value      Units  \n",
      "1                   pida.op         20          %  \n",
      "2                   pida.op         10          %  \n",
      "3                   pida.op          0          %  \n",
      "4                 pida.mode        MAN        NaN  \n",
      "5                       NaN        NaN        NaN  \n",
      "6                 DEAERATOR        NaN        NaN  \n",
      "7                 DEAERATOR        NaN        NaN  \n",
      "8  EFFULUENT CHANEL OLD W/S        NaN        NaN  \n",
      "9  EFFULUENT CHANEL OLD W/S    8.93968         pH  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Skip the first 6 rows, and let pandas use row 7 as the header\n",
    "data = pd.read_csv(\"./PVC-I (Jan, Feb, Mar) EVENTS/01feb.csv\", skiprows=7, on_bad_lines='skip')\n",
    "\n",
    "# Display first few rows\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c18d5f-2558-4ec8-ab72-b84ec9346381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93fd4218-b4b4-40b4-9ddb-367ab8e36b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Event Time</td>\n",
       "      <td>Location Tag</td>\n",
       "      <td>Source</td>\n",
       "      <td>Condition</td>\n",
       "      <td>Action</td>\n",
       "      <td>Priority</td>\n",
       "      <td>Description</td>\n",
       "      <td>Value</td>\n",
       "      <td>Units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2025 23:59:13.104</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>20</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/1/2025 23:58:40.313</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>10</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/1/2025 23:58:26.196</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/1/2025 23:58:23.521</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.mode</td>\n",
       "      <td>MAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2/1/2025 23:57:55.465</td>\n",
       "      <td>IOLINK01_1</td>\n",
       "      <td>AIOR-103</td>\n",
       "      <td>OP Fail in circuit/field wire</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2/1/2025 23:57:42.150</td>\n",
       "      <td>8800</td>\n",
       "      <td>TI8808</td>\n",
       "      <td>ALARM</td>\n",
       "      <td>ACK PNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEAERATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/1/2025 23:57:42.150</td>\n",
       "      <td>8800</td>\n",
       "      <td>TI8808</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEAERATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2/1/2025 23:57:38.385</td>\n",
       "      <td>8100</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFFULUENT CHANEL OLD W/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2/1/2025 23:56:54.100</td>\n",
       "      <td>8100</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H 00</td>\n",
       "      <td>EFFULUENT CHANEL OLD W/S</td>\n",
       "      <td>8.93968</td>\n",
       "      <td>pH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0    Unnamed: 1 Unnamed: 2  \\\n",
       "0             Event Time  Location Tag     Source   \n",
       "1  2/1/2025 23:59:13.104          8800    PIC8808   \n",
       "2  2/1/2025 23:58:40.313          8800    PIC8808   \n",
       "3  2/1/2025 23:58:26.196          8800    PIC8808   \n",
       "4  2/1/2025 23:58:23.521          8800    PIC8808   \n",
       "5  2/1/2025 23:57:55.465    IOLINK01_1   AIOR-103   \n",
       "6  2/1/2025 23:57:42.150          8800     TI8808   \n",
       "7  2/1/2025 23:57:42.150          8800     TI8808   \n",
       "8  2/1/2025 23:57:38.385          8100    AI_PH10   \n",
       "9  2/1/2025 23:56:54.100          8100    AI_PH10   \n",
       "\n",
       "                      Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
       "0                      Condition     Action   Priority   \n",
       "1                         CHANGE        NaN        NaN   \n",
       "2                         CHANGE        NaN        NaN   \n",
       "3                         CHANGE        NaN        NaN   \n",
       "4                         CHANGE        NaN        NaN   \n",
       "5  OP Fail in circuit/field wire        ACK        NaN   \n",
       "6                          ALARM    ACK PNT        NaN   \n",
       "7                          PVLOW        ACK        NaN   \n",
       "8                         PVHIHI        ACK        NaN   \n",
       "9                         PVHIHI        NaN       H 00   \n",
       "\n",
       "                 Unnamed: 6 Unnamed: 7 Unnamed: 8  \n",
       "0               Description      Value      Units  \n",
       "1                   pida.op         20          %  \n",
       "2                   pida.op         10          %  \n",
       "3                   pida.op          0          %  \n",
       "4                 pida.mode        MAN        NaN  \n",
       "5                       NaN        NaN        NaN  \n",
       "6                 DEAERATOR        NaN        NaN  \n",
       "7                 DEAERATOR        NaN        NaN  \n",
       "8  EFFULUENT CHANEL OLD W/S        NaN        NaN  \n",
       "9  EFFULUENT CHANEL OLD W/S    8.93968         pH  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18890ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\n",
    "    \"Event Time\", \"Location Tag\", \"Source\", \"Condition\", \"Action\",\n",
    "    \"Priority\", \"Description\", \"Value\", \"Units\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c25acab-0a4f-4c13-8c5e-47319b720642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>Location Tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Action</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Event Time</td>\n",
       "      <td>Location Tag</td>\n",
       "      <td>Source</td>\n",
       "      <td>Condition</td>\n",
       "      <td>Action</td>\n",
       "      <td>Priority</td>\n",
       "      <td>Description</td>\n",
       "      <td>Value</td>\n",
       "      <td>Units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2025 23:59:13.104</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>20</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/1/2025 23:58:40.313</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>10</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/1/2025 23:58:26.196</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/1/2025 23:58:23.521</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.mode</td>\n",
       "      <td>MAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2/1/2025 23:57:55.465</td>\n",
       "      <td>IOLINK01_1</td>\n",
       "      <td>AIOR-103</td>\n",
       "      <td>OP Fail in circuit/field wire</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2/1/2025 23:57:42.150</td>\n",
       "      <td>8800</td>\n",
       "      <td>TI8808</td>\n",
       "      <td>ALARM</td>\n",
       "      <td>ACK PNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEAERATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/1/2025 23:57:42.150</td>\n",
       "      <td>8800</td>\n",
       "      <td>TI8808</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEAERATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2/1/2025 23:57:38.385</td>\n",
       "      <td>8100</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFFULUENT CHANEL OLD W/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2/1/2025 23:56:54.100</td>\n",
       "      <td>8100</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H 00</td>\n",
       "      <td>EFFULUENT CHANEL OLD W/S</td>\n",
       "      <td>8.93968</td>\n",
       "      <td>pH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Event Time  Location Tag    Source  \\\n",
       "0             Event Time  Location Tag    Source   \n",
       "1  2/1/2025 23:59:13.104          8800   PIC8808   \n",
       "2  2/1/2025 23:58:40.313          8800   PIC8808   \n",
       "3  2/1/2025 23:58:26.196          8800   PIC8808   \n",
       "4  2/1/2025 23:58:23.521          8800   PIC8808   \n",
       "5  2/1/2025 23:57:55.465    IOLINK01_1  AIOR-103   \n",
       "6  2/1/2025 23:57:42.150          8800    TI8808   \n",
       "7  2/1/2025 23:57:42.150          8800    TI8808   \n",
       "8  2/1/2025 23:57:38.385          8100   AI_PH10   \n",
       "9  2/1/2025 23:56:54.100          8100   AI_PH10   \n",
       "\n",
       "                       Condition   Action  Priority               Description  \\\n",
       "0                      Condition   Action  Priority               Description   \n",
       "1                         CHANGE      NaN       NaN                   pida.op   \n",
       "2                         CHANGE      NaN       NaN                   pida.op   \n",
       "3                         CHANGE      NaN       NaN                   pida.op   \n",
       "4                         CHANGE      NaN       NaN                 pida.mode   \n",
       "5  OP Fail in circuit/field wire      ACK       NaN                       NaN   \n",
       "6                          ALARM  ACK PNT       NaN                 DEAERATOR   \n",
       "7                          PVLOW      ACK       NaN                 DEAERATOR   \n",
       "8                         PVHIHI      ACK       NaN  EFFULUENT CHANEL OLD W/S   \n",
       "9                         PVHIHI      NaN      H 00  EFFULUENT CHANEL OLD W/S   \n",
       "\n",
       "     Value  Units  \n",
       "0    Value  Units  \n",
       "1       20      %  \n",
       "2       10      %  \n",
       "3        0      %  \n",
       "4      MAN    NaN  \n",
       "5      NaN    NaN  \n",
       "6      NaN    NaN  \n",
       "7      NaN    NaN  \n",
       "8      NaN    NaN  \n",
       "9  8.93968     pH  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "086826ad-c6fe-4f3f-a842-52c07bd423a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>Location Tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Action</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2025 23:59:13.104</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>20</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/1/2025 23:58:40.313</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>10</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/1/2025 23:58:26.196</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/1/2025 23:58:23.521</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.mode</td>\n",
       "      <td>MAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2/1/2025 23:57:55.465</td>\n",
       "      <td>IOLINK01_1</td>\n",
       "      <td>AIOR-103</td>\n",
       "      <td>OP Fail in circuit/field wire</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>2/1/2025 0:00:11.300</td>\n",
       "      <td>IOLINK04_1</td>\n",
       "      <td>AIOR-704</td>\n",
       "      <td>OP Fail in circuit/field wire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H 15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Channel_18_A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>2/1/2025 0:00:03.900</td>\n",
       "      <td>01</td>\n",
       "      <td>EVENT_SCM2A</td>\n",
       "      <td>OFFNRM</td>\n",
       "      <td>OK</td>\n",
       "      <td>J 00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>2/1/2025 0:00:02.000</td>\n",
       "      <td>1300</td>\n",
       "      <td>XSV1318B</td>\n",
       "      <td>CMDDIS</td>\n",
       "      <td>OK</td>\n",
       "      <td>L 00</td>\n",
       "      <td>RE1301B DISCHARGE</td>\n",
       "      <td>Inbet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>2/1/2025 0:00:02.585</td>\n",
       "      <td>1300</td>\n",
       "      <td>XSV1318B</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>devctla.gop</td>\n",
       "      <td>S0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>2/1/2025 0:00:00.688</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>DAILY RP</td>\n",
       "      <td>PERIODIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>Report Periodic Request</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5020 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Event Time Location Tag       Source  \\\n",
       "1     2/1/2025 23:59:13.104         8800      PIC8808   \n",
       "2     2/1/2025 23:58:40.313         8800      PIC8808   \n",
       "3     2/1/2025 23:58:26.196         8800      PIC8808   \n",
       "4     2/1/2025 23:58:23.521         8800      PIC8808   \n",
       "5     2/1/2025 23:57:55.465   IOLINK01_1     AIOR-103   \n",
       "...                     ...          ...          ...   \n",
       "5016   2/1/2025 0:00:11.300   IOLINK04_1     AIOR-704   \n",
       "5017   2/1/2025 0:00:03.900           01  EVENT_SCM2A   \n",
       "5018   2/1/2025 0:00:02.000         1300     XSV1318B   \n",
       "5019   2/1/2025 0:00:02.585         1300     XSV1318B   \n",
       "5020   2/1/2025 0:00:00.688   SERVER_PVC     DAILY RP   \n",
       "\n",
       "                          Condition Action Priority              Description  \\\n",
       "1                            CHANGE    NaN      NaN                  pida.op   \n",
       "2                            CHANGE    NaN      NaN                  pida.op   \n",
       "3                            CHANGE    NaN      NaN                  pida.op   \n",
       "4                            CHANGE    NaN      NaN                pida.mode   \n",
       "5     OP Fail in circuit/field wire    ACK      NaN                      NaN   \n",
       "...                             ...    ...      ...                      ...   \n",
       "5016  OP Fail in circuit/field wire    NaN     H 15                      NaN   \n",
       "5017                         OFFNRM     OK     J 00                      NaN   \n",
       "5018                         CMDDIS     OK     L 00        RE1301B DISCHARGE   \n",
       "5019                         CHANGE    NaN      NaN              devctla.gop   \n",
       "5020                       PERIODIC    NaN     J 00  Report Periodic Request   \n",
       "\n",
       "             Value Units  \n",
       "1               20     %  \n",
       "2               10     %  \n",
       "3                0     %  \n",
       "4              MAN   NaN  \n",
       "5              NaN   NaN  \n",
       "...            ...   ...  \n",
       "5016  Channel_18_A   NaN  \n",
       "5017           OFF   NaN  \n",
       "5018         Inbet   NaN  \n",
       "5019            S0   NaN  \n",
       "5020            12   NaN  \n",
       "\n",
       "[5020 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[1:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8a23669-4a77-4d14-ad7d-e26b75ffa07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Event Time\n",
      "0  02/01/2025 12:00:00 AM\n",
      "1  02/01/2025 12:00:02 AM\n",
      "2  02/01/2025 12:00:02 AM\n",
      "3  02/01/2025 12:00:03 AM\n",
      "4  02/01/2025 12:00:11 AM\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Event Time' column to proper datetime format\n",
    "data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n",
    "\n",
    "# Sort the dataframe by this datetime column (from earliest → latest)\n",
    "data = data.sort_values(by='Event Time')\n",
    "\n",
    "# Format the column with AM/PM style (e.g. 2025-02-01 11:59:13 PM)\n",
    "data['Event Time'] = data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Reset index after sorting (optional)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "print(data[['Event Time']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae4fa942-6c72-4aaa-9de1-bebff47a9e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>Location Tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Action</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>02/01/2025 11:56:33 PM</td>\n",
       "      <td>1300</td>\n",
       "      <td>XSV1349A</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>devctla.gop</td>\n",
       "      <td>S0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>02/01/2025 11:56:54 PM</td>\n",
       "      <td>8100</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H 00</td>\n",
       "      <td>EFFULUENT CHANEL OLD W/S</td>\n",
       "      <td>8.93968</td>\n",
       "      <td>pH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>02/01/2025 11:57:38 PM</td>\n",
       "      <td>8100</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFFULUENT CHANEL OLD W/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>02/01/2025 11:57:42 PM</td>\n",
       "      <td>8800</td>\n",
       "      <td>TI8808</td>\n",
       "      <td>ALARM</td>\n",
       "      <td>ACK PNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEAERATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>02/01/2025 11:57:42 PM</td>\n",
       "      <td>8800</td>\n",
       "      <td>TI8808</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEAERATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>02/01/2025 11:57:55 PM</td>\n",
       "      <td>IOLINK01_1</td>\n",
       "      <td>AIOR-103</td>\n",
       "      <td>OP Fail in circuit/field wire</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>02/01/2025 11:58:23 PM</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.mode</td>\n",
       "      <td>MAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>02/01/2025 11:58:26 PM</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>02/01/2025 11:58:40 PM</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>10</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>02/01/2025 11:59:13 PM</td>\n",
       "      <td>8800</td>\n",
       "      <td>PIC8808</td>\n",
       "      <td>CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pida.op</td>\n",
       "      <td>20</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Event Time Location Tag    Source  \\\n",
       "5010  02/01/2025 11:56:33 PM         1300  XSV1349A   \n",
       "5011  02/01/2025 11:56:54 PM         8100   AI_PH10   \n",
       "5012  02/01/2025 11:57:38 PM         8100   AI_PH10   \n",
       "5013  02/01/2025 11:57:42 PM         8800    TI8808   \n",
       "5014  02/01/2025 11:57:42 PM         8800    TI8808   \n",
       "5015  02/01/2025 11:57:55 PM   IOLINK01_1  AIOR-103   \n",
       "5016  02/01/2025 11:58:23 PM         8800   PIC8808   \n",
       "5017  02/01/2025 11:58:26 PM         8800   PIC8808   \n",
       "5018  02/01/2025 11:58:40 PM         8800   PIC8808   \n",
       "5019  02/01/2025 11:59:13 PM         8800   PIC8808   \n",
       "\n",
       "                          Condition   Action Priority  \\\n",
       "5010                         CHANGE      NaN      NaN   \n",
       "5011                         PVHIHI      NaN     H 00   \n",
       "5012                         PVHIHI      ACK      NaN   \n",
       "5013                          ALARM  ACK PNT      NaN   \n",
       "5014                          PVLOW      ACK      NaN   \n",
       "5015  OP Fail in circuit/field wire      ACK      NaN   \n",
       "5016                         CHANGE      NaN      NaN   \n",
       "5017                         CHANGE      NaN      NaN   \n",
       "5018                         CHANGE      NaN      NaN   \n",
       "5019                         CHANGE      NaN      NaN   \n",
       "\n",
       "                   Description    Value Units  \n",
       "5010               devctla.gop       S0   NaN  \n",
       "5011  EFFULUENT CHANEL OLD W/S  8.93968    pH  \n",
       "5012  EFFULUENT CHANEL OLD W/S      NaN   NaN  \n",
       "5013                 DEAERATOR      NaN   NaN  \n",
       "5014                 DEAERATOR      NaN   NaN  \n",
       "5015                       NaN      NaN   NaN  \n",
       "5016                 pida.mode      MAN   NaN  \n",
       "5017                   pida.op        0     %  \n",
       "5018                   pida.op       10     %  \n",
       "5019                   pida.op       20     %  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83a99e-f3c6-4b2f-88da-042900d762c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Skip the first 6 rows, and let pandas use row 7 as the header\n",
    "data = pd.read_csv(\"./PVC-I (Jan, Feb, Mar) EVENTS/01feb.csv\", skiprows=7, on_bad_lines='skip')\n",
    "data.columns = [\n",
    "    \"Event Time\", \"Location Tag\", \"Source\", \"Condition\", \"Action\",\n",
    "    \"Priority\", \"Description\", \"Value\", \"Units\"\n",
    "]\n",
    "\n",
    "# Convert 'Event Time' column to proper datetime format\n",
    "data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n",
    "\n",
    "# Sort the dataframe by this datetime column (from earliest → latest)\n",
    "data = data.sort_values(by='Event Time')\n",
    "\n",
    "# Format the column with AM/PM style (e.g. 2025-02-01 11:59:13 PM)\n",
    "data['Event Time'] = data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Reset index after sorting (optional)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display first few rows\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "458fa849-3f12-4b76-9d02-72116451ba62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\01feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\02feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\03feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\04feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\05feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\06feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\07feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\08feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\10feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\11feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\12feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\13feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\14feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\15feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\16feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\17feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\18feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\19feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\20feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\21feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\22feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\23feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\24feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\25feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\26feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\27feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\28feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\9feb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\3701692928.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All February files merged and saved to: ./PVC-I (Jan, Feb, Mar) EVENTS/All_Feb_Combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory where your CSVs are stored\n",
    "folder_path = \"./PVC-I (Jan, Feb, Mar) EVENTS/\"\n",
    "\n",
    "# Find all February CSV files (filenames like 01feb.csv, 02feb.csv, etc.)\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*feb.csv\"))\n",
    "\n",
    "# List to collect all processed DataFrames\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # Read CSV while skipping metadata rows\n",
    "    data = pd.read_csv(file, skiprows=6, on_bad_lines='skip')\n",
    "\n",
    "    # Rename columns\n",
    "    data.columns = [\n",
    "        \"Event Time\", \"Location Tag\", \"Source\", \"Condition\", \"Action\",\n",
    "        \"Priority\", \"Description\", \"Value\", \"Units\"\n",
    "    ]\n",
    "\n",
    "    # Convert 'Event Time' column to datetime\n",
    "    data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n",
    "\n",
    "    # Sort by datetime\n",
    "    data = data.sort_values(by='Event Time')\n",
    "\n",
    "    # Format datetime into AM/PM format\n",
    "    data['Event Time'] = data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # Add processed data to list\n",
    "    all_data.append(data)\n",
    "\n",
    "# Merge all February DataFrames\n",
    "merged_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined result to a new CSV\n",
    "output_file = os.path.join(folder_path, \"All_Feb_Combined.csv\")\n",
    "merged_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ All February files merged and saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8575b0cd-92c9-4c43-aa0e-9c3dda8ea042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\597434298.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['Event Time'] = pd.to_datetime(merged_data['Event Time'])\n"
     ]
    }
   ],
   "source": [
    "merged_data['Event Time'] = pd.to_datetime(merged_data['Event Time'])\n",
    "merged_data = merged_data.sort_values(by='Event Time').reset_index(drop=True)\n",
    "merged_data['Event Time'] = merged_data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "merged_data.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72533fee-c366-4812-9d60-ad31991ec9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\01March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\02March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\03March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\04March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\05March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\06March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\07March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\08March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\09March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\10March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\11March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\12March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\13March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\14March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\15March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\16March.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\17march.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\2905769966.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All March files merged and saved to: ./PVC-I (Jan, Feb, Mar) EVENTS/All_March_Combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory where your CSVs are stored\n",
    "folder_path = \"./PVC-I (Jan, Feb, Mar) EVENTS/\"\n",
    "\n",
    "# Find all February CSV files (filenames like 01feb.csv, 02feb.csv, etc.)\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*march.csv\"))\n",
    "\n",
    "# List to collect all processed DataFrames\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # Read CSV while skipping metadata rows\n",
    "    data = pd.read_csv(file, skiprows=6, on_bad_lines='skip')\n",
    "\n",
    "    # Rename columns\n",
    "    data.columns = [\n",
    "        \"Event Time\", \"Location Tag\", \"Source\", \"Condition\", \"Action\",\n",
    "        \"Priority\", \"Description\", \"Value\", \"Units\"\n",
    "    ]\n",
    "\n",
    "    # Convert 'Event Time' column to datetime\n",
    "    data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n",
    "\n",
    "    # Sort by datetime\n",
    "    data = data.sort_values(by='Event Time')\n",
    "\n",
    "    # Format datetime into AM/PM format\n",
    "    data['Event Time'] = data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # Add processed data to list\n",
    "    all_data.append(data)\n",
    "\n",
    "# Merge all February DataFrames\n",
    "merged_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined result to a new CSV\n",
    "output_file = os.path.join(folder_path, \"All_March_Combined.csv\")\n",
    "merged_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ All March files merged and saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5d7550a-2686-4668-8d5d-d2b3796f455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\597434298.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['Event Time'] = pd.to_datetime(merged_data['Event Time'])\n"
     ]
    }
   ],
   "source": [
    "merged_data['Event Time'] = pd.to_datetime(merged_data['Event Time'])\n",
    "merged_data = merged_data.sort_values(by='Event Time').reset_index(drop=True)\n",
    "merged_data['Event Time'] = merged_data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "merged_data.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2bc6ee1-b2b4-4470-b231-7c372642d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\04jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\05jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\08jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\10jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\11jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\12jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\13jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\14jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\15jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\16jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\17jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\18jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\19jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\1jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\20jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\4178054909.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./PVC-I (Jan, Feb, Mar) EVENTS\\21jan.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 10 elements, new values have 9 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m data = pd.read_csv(file, skiprows=\u001b[32m6\u001b[39m, on_bad_lines=\u001b[33m'\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Rename columns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m = [\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEvent Time\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLocation Tag\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSource\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCondition\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPriority\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDescription\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnits\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m ]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Convert 'Event Time' column to datetime\u001b[39;00m\n\u001b[32m     27\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mEvent Time\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(data[\u001b[33m'\u001b[39m\u001b[33mEvent Time\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Cybergen\\engro project\\alarm_system_RND\\evnv\\Lib\\site-packages\\pandas\\core\\generic.py:6335\u001b[39m, in \u001b[36mNDFrame.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m   6333\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   6334\u001b[39m     \u001b[38;5;28mobject\u001b[39m.\u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[32m-> \u001b[39m\u001b[32m6335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   6337\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:69\u001b[39m, in \u001b[36mpandas._libs.properties.AxisProperty.__set__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Cybergen\\engro project\\alarm_system_RND\\evnv\\Lib\\site-packages\\pandas\\core\\generic.py:817\u001b[39m, in \u001b[36mNDFrame._set_axis\u001b[39m\u001b[34m(self, axis, labels)\u001b[39m\n\u001b[32m    812\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[33;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[32m    814\u001b[39m \u001b[33;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[32m    815\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    816\u001b[39m labels = ensure_index(labels)\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Cybergen\\engro project\\alarm_system_RND\\evnv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[39m, in \u001b[36mBaseBlockManager.set_axis\u001b[39m\u001b[34m(self, axis, new_labels)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m.axes[axis] = new_labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Cybergen\\engro project\\alarm_system_RND\\evnv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[39m, in \u001b[36mDataManager._validate_set_axis\u001b[39m\u001b[34m(self, axis, new_labels)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m new_len != old_len:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     99\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements, new \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length mismatch: Expected axis has 10 elements, new values have 9 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory where your CSVs are stored\n",
    "folder_path = \"./PVC-I (Jan, Feb, Mar) EVENTS/\"\n",
    "\n",
    "# Find all February CSV files (filenames like 01feb.csv, 02feb.csv, etc.)\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*jan.csv\"))\n",
    "\n",
    "# List to collect all processed DataFrames\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # Read CSV while skipping metadata rows\n",
    "    data = pd.read_csv(file, skiprows=6, on_bad_lines='skip')\n",
    "\n",
    "    # Rename columns\n",
    "    data.columns = [\n",
    "        \"Event Time\", \"Location Tag\", \"Source\", \"Condition\", \"Action\",\n",
    "        \"Priority\", \"Description\", \"Value\", \"Units\"\n",
    "    ]\n",
    "\n",
    "    # Convert 'Event Time' column to datetime\n",
    "    data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n",
    "\n",
    "    # Sort by datetime\n",
    "    data = data.sort_values(by='Event Time')\n",
    "\n",
    "    # Format datetime into AM/PM format\n",
    "    data['Event Time'] = data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # Add processed data to list\n",
    "    all_data.append(data)\n",
    "\n",
    "# Merge all February DataFrames\n",
    "merged_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined result to a new CSV\n",
    "output_file = os.path.join(folder_path, \"All_jan_Combined.csv\")\n",
    "merged_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ All Jan files merged and saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91b03959-c04d-484e-b5eb-0873fcda9e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 04jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 05jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 08jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 10jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 11jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 12jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 13jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 14jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 15jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 16jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 17jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 18jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 19jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 1jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 20jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 21jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 22jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 23jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 24jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 25jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 26jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 27jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 28jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 29jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 2jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 30jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 31jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 3jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 6jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 7jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing file: 9jan.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\90506033.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All January files merged successfully and saved to: ./PVC-I (Jan, Feb, Mar) EVENTS/All_Jan_Combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory where your CSVs are stored\n",
    "folder_path = \"./PVC-I (Jan, Feb, Mar) EVENTS/\"\n",
    "\n",
    "# Find all January CSV files (filenames like 01jan.csv, 02jan.csv, etc.)\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*jan.csv\"))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    print(f\"📂 Processing file: {os.path.basename(file)}\")\n",
    "\n",
    "    # Read CSV while skipping metadata rows\n",
    "    data = pd.read_csv(file, skiprows=6, on_bad_lines='skip')\n",
    "\n",
    "    # Drop the extra empty column if it exists\n",
    "    if len(data.columns) == 10:\n",
    "        data = data.iloc[:, :9]  # keep only first 9 columns\n",
    "\n",
    "    # Rename columns\n",
    "    data.columns = [\n",
    "        \"Event Time\", \"Location Tag\", \"Source\", \"Condition\", \"Action\",\n",
    "        \"Priority\", \"Description\", \"Value\", \"Units\"\n",
    "    ]\n",
    "\n",
    "    # Convert 'Event Time' column to datetime\n",
    "    data['Event Time'] = pd.to_datetime(data['Event Time'], errors='coerce')\n",
    "\n",
    "    # Sort by datetime\n",
    "    data = data.sort_values(by='Event Time')\n",
    "\n",
    "    # Format datetime into AM/PM format\n",
    "    data['Event Time'] = data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # Add processed data to list\n",
    "    all_data.append(data)\n",
    "\n",
    "# Merge all January DataFrames\n",
    "merged_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined result to a new CSV\n",
    "output_file = os.path.join(folder_path, \"All_Jan_Combined.csv\")\n",
    "merged_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ All January files merged successfully and saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de90ae67-fdc9-485b-b057-33ca3189d548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_4016\\597434298.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['Event Time'] = pd.to_datetime(merged_data['Event Time'])\n"
     ]
    }
   ],
   "source": [
    "merged_data['Event Time'] = pd.to_datetime(merged_data['Event Time'])\n",
    "merged_data = merged_data.sort_values(by='Event Time').reset_index(drop=True)\n",
    "merged_data['Event Time'] = merged_data['Event Time'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "merged_data.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5d49f-ab72-44b1-aa4b-8b0912001bd2",
   "metadata": {},
   "source": [
    "# Calculations Starting from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91b3f5f7-e976-4691-876e-6b916f15fd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Event Time Location Tag    Source                      Condition  \\\n",
      "0 2025-01-01 00:00:00   SERVER_PVC  DAILY RP                       PERIODIC   \n",
      "1 2025-01-01 00:00:03         1600    PI1601                         PVLOLO   \n",
      "2 2025-01-01 00:00:04         1500    TI1507                          PVLOW   \n",
      "3 2025-01-01 00:00:05   IOLINK04_1  AIOR-704  OP Fail in circuit/field wire   \n",
      "4 2025-01-01 00:00:07         1200   TIC1203                         PVHIHI   \n",
      "\n",
      "  Action Priority              Description         Value    Units  Unnamed: 9  \\\n",
      "0    NaN     J 00  Report Periodic Request            12      NaN         NaN   \n",
      "1    NaN     J 00            HE1601 OUTLET      0.239591  kg/cm2G         NaN   \n",
      "2    ACK      NaN            TW1501 BOTTOM           NaN      NaN         NaN   \n",
      "3     OK     H 15                      NaN  Channel_18_B      NaN         NaN   \n",
      "4    NaN     H 00          HE1203 D/S TEMP       88.7875        C         NaN   \n",
      "\n",
      "   Unnamed: 10    Unnamed: 11    Unnamed: 12  \n",
      "0          NaN            NaN            NaN  \n",
      "1          NaN            NaN            NaN  \n",
      "2          NaN            NaN            NaN  \n",
      "3          NaN  Unique Source  Blank Actions  \n",
      "4          NaN           1076         334468  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read specific sheet from Excel file\n",
    "jan_df = pd.read_excel('./PVC-I (Jan, Feb, Mar) EVENTS/all_jan_combined.xlsx', sheet_name='All_Jan_Combined')\n",
    "feb_df = pd.read_excel('./PVC-I (Jan, Feb, Mar) EVENTS/all_jan_combined.xlsx', sheet_name='All_Feb_Combined')\n",
    "march_df = pd.read_excel('./PVC-I (Jan, Feb, Mar) EVENTS/all_jan_combined.xlsx', sheet_name='All_March_Combined')\n",
    "# Display the first few rows\n",
    "print(jan_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7121ff4e-ac19-4fae-9041-48d50861cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([jan_df, feb_df, march_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f634bbb4-670b-49ff-a2ce-8401438f8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns = merged_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7e3e4c9-2e76-4859-95c5-fd92e44c3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df= merged_df[['Event Time','Location Tag','Source','Condition','Action','Priority','Description','Value','Units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "039f09fc-9303-4c7e-b07d-ec7209ddd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('All_Merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57f352ce-25ed-407c-8345-1b65e910909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Clean columns\n",
    "# merged_df['Source'] = merged_df['Source'].astype(str).str.strip()\n",
    "# merged_df['Action'] = df['Action'].astype(str).str.strip()\n",
    "merged_df['Event Time'] = pd.to_datetime(merged_df['Event Time'])\n",
    "merged_df = merged_df[merged_df['Source'].notna() & (merged_df['Source'] != \"\")]\n",
    "merged_df = merged_df.sort_values(['Source', 'Event Time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c1fe2-b8c3-4053-8652-d04b1fe0d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Action'] = df['Action'].astype(str).str.strip().replace({'nan': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b3aee84-017b-4539-be53-940388569b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>Location Tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Action</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 01:59:46</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Command</td>\n",
       "      <td></td>\n",
       "      <td>J 00</td>\n",
       "      <td>RCM;$330013f2cdc9e162-0006</td>\n",
       "      <td>Start</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 01:59:47</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td></td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2cdc9e162-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 01:59:47</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>State Change</td>\n",
       "      <td></td>\n",
       "      <td>J 00</td>\n",
       "      <td>RCM;$330013f2cdc9e162-0006</td>\n",
       "      <td>Running</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01 01:59:47</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td></td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2cdc9e162-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 01:59:47</td>\n",
       "      <td>01</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>Formula</td>\n",
       "      <td></td>\n",
       "      <td>J 00</td>\n",
       "      <td>DATA;$330013f2cdc9e162-0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903224</th>\n",
       "      <td>2025-03-14 22:55:00</td>\n",
       "      <td>8800</td>\n",
       "      <td>YI8841</td>\n",
       "      <td>OFFNRM</td>\n",
       "      <td></td>\n",
       "      <td>L 00</td>\n",
       "      <td>PURGE DEMAND</td>\n",
       "      <td>PURGE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903225</th>\n",
       "      <td>2025-03-14 22:55:00</td>\n",
       "      <td>8800</td>\n",
       "      <td>YI8841</td>\n",
       "      <td>OFFNRM</td>\n",
       "      <td>OK</td>\n",
       "      <td>L 00</td>\n",
       "      <td>PURGE DEMAND</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903226</th>\n",
       "      <td>2025-03-14 22:56:00</td>\n",
       "      <td>8800</td>\n",
       "      <td>YI8841</td>\n",
       "      <td>OFFNRM</td>\n",
       "      <td></td>\n",
       "      <td>L 00</td>\n",
       "      <td>PURGE DEMAND</td>\n",
       "      <td>PURGE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903227</th>\n",
       "      <td>2025-03-14 22:57:00</td>\n",
       "      <td>8800</td>\n",
       "      <td>YI8841</td>\n",
       "      <td>OFFNRM</td>\n",
       "      <td>OK</td>\n",
       "      <td>L 00</td>\n",
       "      <td>PURGE DEMAND</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903228</th>\n",
       "      <td>2025-03-14 23:16:00</td>\n",
       "      <td>8800</td>\n",
       "      <td>YI8841</td>\n",
       "      <td>OFFNRM</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PURGE DEMAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903229 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Event Time Location Tag                      Source  \\\n",
       "0      2025-01-01 01:59:46           01  $ACTIVITY_330413F2352AB609   \n",
       "1      2025-01-01 01:59:47           01  $ACTIVITY_330413F2352AB609   \n",
       "2      2025-01-01 01:59:47           01  $ACTIVITY_330413F2352AB609   \n",
       "3      2025-01-01 01:59:47           01  $ACTIVITY_330413F2352AB609   \n",
       "4      2025-01-01 01:59:47           01  $ACTIVITY_330413F2352AB609   \n",
       "...                    ...          ...                         ...   \n",
       "903224 2025-03-14 22:55:00         8800                      YI8841   \n",
       "903225 2025-03-14 22:55:00         8800                      YI8841   \n",
       "903226 2025-03-14 22:56:00         8800                      YI8841   \n",
       "903227 2025-03-14 22:57:00         8800                      YI8841   \n",
       "903228 2025-03-14 23:16:00         8800                      YI8841   \n",
       "\n",
       "           Condition Action Priority                  Description    Value  \\\n",
       "0            Command            J 00   RCM;$330013f2cdc9e162-0006    Start   \n",
       "1            Formula            J 00  DATA;$330013f2cdc9e162-0006      NaN   \n",
       "2       State Change            J 00   RCM;$330013f2cdc9e162-0006  Running   \n",
       "3            Formula            J 00  DATA;$330013f2cdc9e162-0006      NaN   \n",
       "4            Formula            J 00  DATA;$330013f2cdc9e162-0006      NaN   \n",
       "...              ...    ...      ...                          ...      ...   \n",
       "903224        OFFNRM            L 00                 PURGE DEMAND    PURGE   \n",
       "903225        OFFNRM     OK     L 00                 PURGE DEMAND   NORMAL   \n",
       "903226        OFFNRM            L 00                 PURGE DEMAND    PURGE   \n",
       "903227        OFFNRM     OK     L 00                 PURGE DEMAND   NORMAL   \n",
       "903228        OFFNRM    ACK      NaN                 PURGE DEMAND      NaN   \n",
       "\n",
       "       Units  \n",
       "0        NaN  \n",
       "1        PPM  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "...      ...  \n",
       "903224   NaN  \n",
       "903225   NaN  \n",
       "903226   NaN  \n",
       "903227   NaN  \n",
       "903228   NaN  \n",
       "\n",
       "[903229 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee6e1e-681d-45b6-87b9-cf8b23fdecff",
   "metadata": {},
   "source": [
    "# Final Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8bdac6c-3780-4db6-b703-17b8e8acd767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>Location Tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Action</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>DAILY RP</td>\n",
       "      <td>PERIODIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>Report Periodic Request</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 00:00:03</td>\n",
       "      <td>1600</td>\n",
       "      <td>PI1601</td>\n",
       "      <td>PVLOLO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>HE1601 OUTLET</td>\n",
       "      <td>0.239591</td>\n",
       "      <td>kg/cm2G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 00:00:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>TI1507</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TW1501 BOTTOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01 00:00:05</td>\n",
       "      <td>IOLINK04_1</td>\n",
       "      <td>AIOR-704</td>\n",
       "      <td>OP Fail in circuit/field wire</td>\n",
       "      <td>OK</td>\n",
       "      <td>H 15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Channel_18_B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 00:00:07</td>\n",
       "      <td>1200</td>\n",
       "      <td>TIC1203</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H 00</td>\n",
       "      <td>HE1203 D/S TEMP</td>\n",
       "      <td>88.7875</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903349</th>\n",
       "      <td>2025-03-17 10:55:00</td>\n",
       "      <td>1300</td>\n",
       "      <td>AI1301</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L 00</td>\n",
       "      <td>VE1306 INLET</td>\n",
       "      <td>5.99933</td>\n",
       "      <td>ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903350</th>\n",
       "      <td>2025-03-17 10:55:00</td>\n",
       "      <td>1300</td>\n",
       "      <td>AI1301</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VE1306 INLET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903351</th>\n",
       "      <td>2025-03-17 10:55:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903352</th>\n",
       "      <td>2025-03-17 10:56:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903353</th>\n",
       "      <td>2025-03-17 10:56:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903354 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Event Time Location Tag    Source  \\\n",
       "0      2025-01-01 00:00:00   SERVER_PVC  DAILY RP   \n",
       "1      2025-01-01 00:00:03         1600    PI1601   \n",
       "2      2025-01-01 00:00:04         1500    TI1507   \n",
       "3      2025-01-01 00:00:05   IOLINK04_1  AIOR-704   \n",
       "4      2025-01-01 00:00:07         1200   TIC1203   \n",
       "...                    ...          ...       ...   \n",
       "903349 2025-03-17 10:55:00         1300    AI1301   \n",
       "903350 2025-03-17 10:55:00         1300    AI1301   \n",
       "903351 2025-03-17 10:55:00   SERVER_PVC       NaN   \n",
       "903352 2025-03-17 10:56:00   SERVER_PVC       NaN   \n",
       "903353 2025-03-17 10:56:00   SERVER_PVC       NaN   \n",
       "\n",
       "                            Condition Action Priority  \\\n",
       "0                            PERIODIC    NaN     J 00   \n",
       "1                              PVLOLO    NaN     J 00   \n",
       "2                               PVLOW    ACK      NaN   \n",
       "3       OP Fail in circuit/field wire     OK     H 15   \n",
       "4                              PVHIHI    NaN     H 00   \n",
       "...                               ...    ...      ...   \n",
       "903349                          PVLOW    NaN     L 00   \n",
       "903350                          PVLOW    ACK      NaN   \n",
       "903351                         Demand    NaN      NaN   \n",
       "903352                         Demand    NaN      NaN   \n",
       "903353                         Demand    NaN      NaN   \n",
       "\n",
       "                      Description         Value    Units  \n",
       "0         Report Periodic Request            12      NaN  \n",
       "1                   HE1601 OUTLET      0.239591  kg/cm2G  \n",
       "2                   TW1501 BOTTOM           NaN      NaN  \n",
       "3                             NaN  Channel_18_B      NaN  \n",
       "4                 HE1203 D/S TEMP       88.7875        C  \n",
       "...                           ...           ...      ...  \n",
       "903349               VE1306 INLET       5.99933       ph  \n",
       "903350               VE1306 INLET           NaN      NaN  \n",
       "903351  CSV export in progress...           NaN      NaN  \n",
       "903352  CSV export in progress...           NaN      NaN  \n",
       "903353  CSV export in progress...           NaN      NaN  \n",
       "\n",
       "[903354 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df= merged_df[['Event Time','Location Tag','Source','Condition','Action','Priority','Description','Value','Units']]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f117dd74-2e3c-4471-85a8-cb4e56fc9fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Sources: 1230\n"
     ]
    }
   ],
   "source": [
    "merged_df_unique_count = merged_df['Source'].nunique()\n",
    "print(f\"Number of unique Sources: {merged_df_unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec6943-e7bb-41f3-a115-eb82a29b31ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dd0de-4435-469a-8bab-600a470dcddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4c7b1aee-8512-4eae-8f63-17950e1d1ab4",
   "metadata": {},
   "source": [
    "✅ What This Version Handles\n",
    "Scenario\tCounted as New Alarm?\n",
    "Blank → ACK → OK\t✅ 1 alarm\n",
    "Blank → ACK → Blank\t✅ 2 alarms\n",
    "Blank → Blank → OK\t✅ 1 alarm\n",
    "Blank → ACK → OK → Blank\t✅ 2 alarms\n",
    "Blank → OK → Blank\t✅ 2 alarms\n",
    "Continuous blanks (no ACK/OK)\t✅ 1 alarm only (still same ongoing alarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2f27e4e-decb-4a0c-a92c-8f5aac043073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_12252\\4050052940.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  alarm_summary = merged_df.groupby('Source').apply(count_unique_alarms).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique alarm count per source:\n",
      "          Source  Unique Alarms\n",
      "150       CI8102           9933\n",
      "603       LI1107           7385\n",
      "60      AIOR-704           3140\n",
      "346  EVENT_SCM1A           3081\n",
      "347  EVENT_SCM1B           3063\n",
      "349  EVENT_SCM2A           2985\n",
      "149       CI8101           2262\n",
      "991     TIC1301A           1562\n",
      "993     TIC1301B           1551\n",
      "385       FI1514           1541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to calculate unique alarms with refined state logic\n",
    "def count_unique_alarms(group):\n",
    "    alarm_count = 0\n",
    "    state = \"IDLE\"  # IDLE, ACTIVE, or ACKED\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        action = row['Action'].upper().strip()\n",
    "\n",
    "        if action == \"\":  # Blank = new or continued alarm\n",
    "            if state == \"IDLE\":\n",
    "                alarm_count += 1\n",
    "                state = \"ACTIVE\"\n",
    "            elif state == \"ACKED\":\n",
    "                # New blank after ACK without OK => new alarm\n",
    "                alarm_count += 1\n",
    "                state = \"ACTIVE\"\n",
    "\n",
    "        elif action == \"ACK\":\n",
    "            if state == \"ACTIVE\":\n",
    "                state = \"ACKED\"\n",
    "\n",
    "        elif action == \"OK\":\n",
    "            state = \"IDLE\"\n",
    "\n",
    "        # Any other actions ignored\n",
    "\n",
    "    return pd.Series({'Unique Alarms': alarm_count})\n",
    "\n",
    "# Apply logic per source\n",
    "alarm_summary = merged_df.groupby('Source').apply(count_unique_alarms).reset_index()\n",
    "\n",
    "print(\"\\nUnique alarm count per source:\")\n",
    "print(alarm_summary.sort_values('Unique Alarms', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e64e1ca9-5e23-4333-bd2f-23ac77771b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Unique Alarms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAH10023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAH10026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAH10027</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAH10028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>XSV8808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>XSV8811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>YI8800LP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>YI8802</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>YI8841</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Source  Unique Alarms\n",
       "0     $ACTIVITY_330413F2352AB609              1\n",
       "1                       AAH10023              1\n",
       "2                       AAH10026              2\n",
       "3                       AAH10027             22\n",
       "4                       AAH10028              1\n",
       "...                          ...            ...\n",
       "1225                     XSV8808              1\n",
       "1226                     XSV8811              1\n",
       "1227                    YI8800LP              6\n",
       "1228                      YI8802             21\n",
       "1229                      YI8841             57\n",
       "\n",
       "[1230 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarm_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae04949-2f88-460c-a84e-1120d232bbea",
   "metadata": {},
   "source": [
    "# Stale and Chattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47519ad3-8269-40c2-be78-5eb3a944ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_12252\\2300381213.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_analyzed = merged_df.groupby('Source', group_keys=False).apply(analyze_alarms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top sources with stale alarms:\n",
      "                         Source  Stale Count\n",
      "928                      REPORT        75762\n",
      "0    $ACTIVITY_330413F2352AB609        53020\n",
      "700                    OP_NASH1        46363\n",
      "345                  EVENT_SCM1        29590\n",
      "346                 EVENT_SCM1A        26988\n",
      "350                 EVENT_SCM2B        25254\n",
      "708                  OP_SUPER_B        22672\n",
      "706                  OP_SUPER_A        22611\n",
      "348                  EVENT_SCM2        21502\n",
      "349                 EVENT_SCM2A        14586\n",
      "\n",
      "Top sources with chattering alarms:\n",
      "          Source  Chattering Count\n",
      "347  EVENT_SCM1B             14106\n",
      "346  EVENT_SCM1A             11668\n",
      "349  EVENT_SCM2A             11182\n",
      "150       CI8102              9740\n",
      "603       LI1107              7279\n",
      "350  EVENT_SCM2B              4534\n",
      "700     OP_NASH1              2036\n",
      "149       CI8101              1976\n",
      "60      AIOR-704              1793\n",
      "420      FIC1501              1537\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Parameters (you can tune)\n",
    "STALE_THRESHOLD_MIN = 30   # 30 minutes without action\n",
    "CHATTER_THRESHOLD_MIN = 10 # 10 minutes between alarms for same source\n",
    "\n",
    "# Detect stale + chattering\n",
    "def analyze_alarms(group):\n",
    "    group = group.copy().reset_index(drop=True)\n",
    "    stale_flags = []\n",
    "    chatter_flags = []\n",
    "    \n",
    "    last_alarm_time = None\n",
    "    last_ok_time = None\n",
    "    state = \"IDLE\"\n",
    "\n",
    "    for i, row in group.iterrows():\n",
    "        action = row['Action'].upper().strip()\n",
    "        time = row['Event Time']\n",
    "\n",
    "        # --- Detect stale alarms ---\n",
    "        if action == \"\":\n",
    "            if state == \"IDLE\":\n",
    "                # New alarm starts\n",
    "                last_alarm_time = time\n",
    "                state = \"ACTIVE\"\n",
    "                stale_flags.append(False)\n",
    "                chatter_flags.append(False)\n",
    "            elif state in [\"ACTIVE\", \"ACKED\"]:\n",
    "                # Alarm continuing without OK or ACK\n",
    "                if (time - last_alarm_time).total_seconds() / 60 > STALE_THRESHOLD_MIN:\n",
    "                    stale_flags.append(True)\n",
    "                else:\n",
    "                    stale_flags.append(False)\n",
    "                chatter_flags.append(False)\n",
    "        elif action == \"ACK\":\n",
    "            if state == \"ACTIVE\":\n",
    "                state = \"ACKED\"\n",
    "            stale_flags.append(False)\n",
    "            chatter_flags.append(False)\n",
    "        elif action == \"OK\":\n",
    "            if state in [\"ACTIVE\", \"ACKED\"]:\n",
    "                state = \"IDLE\"\n",
    "                last_ok_time = time\n",
    "            stale_flags.append(False)\n",
    "            chatter_flags.append(False)\n",
    "        else:\n",
    "            stale_flags.append(False)\n",
    "            chatter_flags.append(False)\n",
    "\n",
    "        # --- Detect chattering (new blank soon after OK or ACK cycle) ---\n",
    "        if action == \"\":\n",
    "            if last_ok_time is not None:\n",
    "                diff_min = (time - last_ok_time).total_seconds() / 60\n",
    "                if diff_min <= CHATTER_THRESHOLD_MIN:\n",
    "                    chatter_flags[-1] = True  # mark latest alarm as chattering\n",
    "\n",
    "    group[\"is_stale\"] = stale_flags\n",
    "    group[\"is_chattering\"] = chatter_flags\n",
    "    return group\n",
    "\n",
    "\n",
    "df_analyzed = merged_df.groupby('Source', group_keys=False).apply(analyze_alarms)\n",
    "\n",
    "# Summary reports\n",
    "stale_summary = df_analyzed.groupby('Source')['is_stale'].sum().reset_index(name='Stale Count')\n",
    "chatter_summary = df_analyzed.groupby('Source')['is_chattering'].sum().reset_index(name='Chattering Count')\n",
    "\n",
    "print(\"\\nTop sources with stale alarms:\")\n",
    "print(stale_summary.sort_values('Stale Count', ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop sources with chattering alarms:\")\n",
    "print(chatter_summary.sort_values('Chattering Count', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784db6d-62e8-480c-b578-0b1a28321176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Read data ---\n",
    "df = pd.read_excel(\"alarms_january.xlsx\")\n",
    "df['Event Time'] = pd.to_datetime(df['Event Time'])\n",
    "df = df.sort_values('Event Time')\n",
    "\n",
    "# --- Filter only relevant columns ---\n",
    "df = df[['Event Time', 'Source', 'Action']]\n",
    "\n",
    "# --- Initialize containers ---\n",
    "alarm_cycles = []\n",
    "\n",
    "# --- Group by each source ---\n",
    "for source, group in df.groupby('Source'):\n",
    "    group = group.sort_values('Event Time').reset_index(drop=True)\n",
    "    current_alarm = None\n",
    "\n",
    "    for i, row in group.iterrows():\n",
    "        action = str(row['Action']).strip().upper()\n",
    "        time = row['Event Time']\n",
    "\n",
    "        # Start of alarm\n",
    "        if action == '' and current_alarm is None:\n",
    "            current_alarm = {'source': source, 'start_time': time, 'ack_time': None, 'ok_time': None}\n",
    "\n",
    "        # Acknowledged\n",
    "        elif action == 'ACK' and current_alarm and current_alarm['ack_time'] is None:\n",
    "            current_alarm['ack_time'] = time\n",
    "\n",
    "        # Cleared\n",
    "        elif action == 'OK' and current_alarm:\n",
    "            current_alarm['ok_time'] = time\n",
    "            alarm_cycles.append(current_alarm)\n",
    "            current_alarm = None  # Reset after cycle completes\n",
    "\n",
    "    # Handle alarms that never cleared\n",
    "    if current_alarm:\n",
    "        alarm_cycles.append(current_alarm)\n",
    "\n",
    "# --- Convert to DataFrame ---\n",
    "cycles_df = pd.DataFrame(alarm_cycles)\n",
    "\n",
    "# --- KPI Calculations ---\n",
    "cycles_df['ack_delay'] = (cycles_df['ack_time'] - cycles_df['start_time']).dt.total_seconds() / 60\n",
    "cycles_df['ok_delay'] = (cycles_df['ok_time'] - cycles_df['start_time']).dt.total_seconds() / 60\n",
    "\n",
    "kpis = {\n",
    "    \"Total Alarms\": len(cycles_df),\n",
    "    \"Unique Sources\": df['Source'].nunique(),\n",
    "    \"Average Ack Time (min)\": round(cycles_df['ack_delay'].mean(), 2),\n",
    "    \"Average Resolve Time (min)\": round(cycles_df['ok_delay'].mean(), 2),\n",
    "    \"Stale Alarms\": cycles_df['ok_time'].isna().sum(),\n",
    "    \"Stale Alarm %\": round(100 * cycles_df['ok_time'].isna().sum() / len(cycles_df), 2),\n",
    "}\n",
    "\n",
    "print(pd.DataFrame([kpis]))\n",
    "bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2293e0a-4065-40ce-9348-68d8aa10ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =====================================================\n",
    "# === KPI ENGINE FOR ALARM MANAGEMENT SYSTEM BACKEND ===\n",
    "# =====================================================\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Prepare and clean alarm event data\"\"\"\n",
    "    df = df.copy()\n",
    "    df['Event Time'] = pd.to_datetime(df['Event Time'], errors='coerce')\n",
    "    df = df.dropna(subset=['Event Time', 'Source'])\n",
    "    df = df.sort_values('Event Time')\n",
    "    df['Action'] = df['Action'].fillna('').str.upper().str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_alarm_cycles(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract complete/incomplete alarm cycles for each source\"\"\"\n",
    "    alarm_cycles = []\n",
    "\n",
    "    for source, group in df.groupby('Source'):\n",
    "        group = group.sort_values('Event Time').reset_index(drop=True)\n",
    "        current_alarm = None\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            action = row['Action']\n",
    "            time = row['Event Time']\n",
    "\n",
    "            if action == '' and current_alarm is None:\n",
    "                current_alarm = {'source': source, 'start_time': time, 'ack_time': None, 'ok_time': None}\n",
    "\n",
    "            elif action == 'ACK' and current_alarm and current_alarm['ack_time'] is None:\n",
    "                current_alarm['ack_time'] = time\n",
    "\n",
    "            elif action == 'OK' and current_alarm:\n",
    "                current_alarm['ok_time'] = time\n",
    "                alarm_cycles.append(current_alarm)\n",
    "                current_alarm = None  # Reset after completion\n",
    "\n",
    "        # Handle unclosed alarm\n",
    "        if current_alarm:\n",
    "            alarm_cycles.append(current_alarm)\n",
    "\n",
    "    cycles_df = pd.DataFrame(alarm_cycles)\n",
    "    if not cycles_df.empty:\n",
    "        cycles_df['ack_delay'] = (cycles_df['ack_time'] - cycles_df['start_time']).dt.total_seconds() / 60\n",
    "        cycles_df['ok_delay'] = (cycles_df['ok_time'] - cycles_df['start_time']).dt.total_seconds() / 60\n",
    "    return cycles_df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# ============== KPI CALCULATION FUNCTIONS ============\n",
    "# =====================================================\n",
    "\n",
    "def kpi_total_alarms(cycles_df: pd.DataFrame) -> int:\n",
    "    return len(cycles_df)\n",
    "\n",
    "\n",
    "def kpi_unique_sources(df: pd.DataFrame) -> int:\n",
    "    return df['Source'].nunique()\n",
    "\n",
    "\n",
    "def kpi_avg_ack_time(cycles_df: pd.DataFrame) -> float:\n",
    "    return round(cycles_df['ack_delay'].mean(), 2) if not cycles_df.empty else 0\n",
    "\n",
    "\n",
    "def kpi_avg_ok_time(cycles_df: pd.DataFrame) -> float:\n",
    "    return round(cycles_df['ok_delay'].mean(), 2) if not cycles_df.empty else 0\n",
    "\n",
    "\n",
    "def kpi_stale_alarms(cycles_df: pd.DataFrame, threshold_min: int = 30) -> int:\n",
    "    \"\"\"Stale if no OK for > threshold\"\"\"\n",
    "    if cycles_df.empty:\n",
    "        return 0\n",
    "    stale = cycles_df[\n",
    "        (cycles_df['ok_time'].isna()) |\n",
    "        ((cycles_df['ok_time'] - cycles_df['start_time']).dt.total_seconds() / 60 > threshold_min)\n",
    "    ]\n",
    "    return len(stale)\n",
    "\n",
    "\n",
    "def kpi_chattering_alarms(cycles_df: pd.DataFrame, gap_min: int = 10) -> int:\n",
    "    \"\"\"Count chattering alarms per source based on time gap between alarms\"\"\"\n",
    "    if cycles_df.empty:\n",
    "        return 0\n",
    "    chatter_count = 0\n",
    "    for source, group in cycles_df.groupby('source'):\n",
    "        group = group.sort_values('start_time').reset_index(drop=True)\n",
    "        group['gap'] = group['start_time'].diff().dt.total_seconds() / 60\n",
    "        chatter_count += group[group['gap'] < gap_min].shape[0]\n",
    "    return chatter_count\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# =============== MAIN KPI WRAPPER ====================\n",
    "# =====================================================\n",
    "\n",
    "def compute_all_kpis(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Main wrapper to compute all KPIs efficiently\"\"\"\n",
    "    df = preprocess_data(df)\n",
    "    cycles_df = get_alarm_cycles(df)\n",
    "\n",
    "    total_alarms = kpi_total_alarms(cycles_df)\n",
    "    stale_alarms = kpi_stale_alarms(cycles_df)\n",
    "    chatter_alarms = kpi_chattering_alarms(cycles_df)\n",
    "\n",
    "    return {\n",
    "        \"total_alarms\": total_alarms,\n",
    "        \"unique_sources\": kpi_unique_sources(df),\n",
    "        \"average_ack_time_min\": kpi_avg_ack_time(cycles_df),\n",
    "        \"average_ok_time_min\": kpi_avg_ok_time(cycles_df),\n",
    "        \"stale_alarms\": stale_alarms,\n",
    "        \"stale_alarm_percent\": round((stale_alarms / total_alarms * 100), 2) if total_alarms else 0,\n",
    "        \"chattering_alarms\": chatter_alarms,\n",
    "        \"chattering_alarm_percent\": round((chatter_alarms / total_alarms * 100), 2) if total_alarms else 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f536ab98-8862-4bb6-ad0f-5f93e44e4510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\142567256.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[event_date_column] = pd.to_datetime(merged_df[event_date_column])\n",
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\142567256.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df['Date'] = merged_df[event_date_column].dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 903354\n",
      "Total alarms (Action is blank/NaN): 757264\n",
      "\n",
      "Alarms per day:\n",
      "Date\n",
      "2025-01-01    18482\n",
      "2025-01-02    13287\n",
      "2025-01-03    16523\n",
      "2025-01-04    13248\n",
      "2025-01-05    11355\n",
      "              ...  \n",
      "2025-03-13     3866\n",
      "2025-03-14    11363\n",
      "2025-03-15    12078\n",
      "2025-03-16    10719\n",
      "2025-03-17     5171\n",
      "Length: 75, dtype: int64\n",
      "\n",
      "--- RESULT ---\n",
      "Average Alarms per Day: 10096.85\n",
      "\n",
      "Total unique days: 75\n",
      "Max alarms in a day: 30374\n",
      "Min alarms in a day: 738\n",
      "Date range: 2025-01-01 to 2025-03-17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# --- Calculate Average Alarms per Day ---\n",
    "\n",
    "# Replace these with your actual column names\n",
    "event_date_column = 'Event Time'  # Column with dates like \"3/1/2025 0:00\"\n",
    "action_column = 'Action'  # Column where blank/NaN means it's an alarm\n",
    "\n",
    "# Convert event date to datetime\n",
    "merged_df[event_date_column] = pd.to_datetime(merged_df[event_date_column])\n",
    "\n",
    "# Extract just the date (without time)\n",
    "merged_df['Date'] = merged_df[event_date_column].dt.date\n",
    "\n",
    "# Filter rows where Action is NaN/blank (these are alarms)\n",
    "alarms_df = merged_df[merged_df[action_column].isna()]\n",
    "\n",
    "print(f\"Total rows: {len(merged_df)}\")\n",
    "print(f\"Total alarms (Action is blank/NaN): {len(alarms_df)}\")\n",
    "\n",
    "# Count alarms per day\n",
    "alarms_per_day = alarms_df.groupby('Date').size()\n",
    "\n",
    "print(f\"\\nAlarms per day:\\n{alarms_per_day}\")\n",
    "\n",
    "# Calculate average alarms per day\n",
    "average_alarms_per_day = alarms_per_day.mean()\n",
    "\n",
    "print(f\"\\n--- RESULT ---\")\n",
    "print(f\"Average Alarms per Day: {average_alarms_per_day:.2f}\")\n",
    "\n",
    "# Additional statistics\n",
    "print(f\"\\nTotal unique days: {len(alarms_per_day)}\")\n",
    "print(f\"Max alarms in a day: {alarms_per_day.max()}\")\n",
    "print(f\"Min alarms in a day: {alarms_per_day.min()}\")\n",
    "print(f\"Date range: {alarms_df['Date'].min()} to {alarms_df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b9366c-aa52-4897-8969-b2c1dc72188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DAYS EXCEEDING LIMIT ---\n",
      "Limit: 288 alarms per day\n",
      "Days exceeding limit: 75\n",
      "Total days: 75\n",
      "Percentage of days exceeding limit: 100.00%\n",
      "\n",
      "Days that exceeded 288 alarms:\n",
      "Date\n",
      "2025-01-01    18482\n",
      "2025-01-02    13287\n",
      "2025-01-03    16523\n",
      "2025-01-04    13248\n",
      "2025-01-05    11355\n",
      "              ...  \n",
      "2025-03-13     3866\n",
      "2025-03-14    11363\n",
      "2025-03-15    12078\n",
      "2025-03-16    10719\n",
      "2025-03-17     5171\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate % of days exceeding 288 alarms ---\n",
    "\n",
    "limit = 288\n",
    "\n",
    "# Count days where alarms exceed the limit\n",
    "days_exceeding_limit = (alarms_per_day > limit).sum()\n",
    "total_days = len(alarms_per_day)\n",
    "\n",
    "# Calculate percentage\n",
    "percentage_exceeding = (days_exceeding_limit / total_days) * 100\n",
    "\n",
    "print(f\"\\n--- DAYS EXCEEDING LIMIT ---\")\n",
    "print(f\"Limit: {limit} alarms per day\")\n",
    "print(f\"Days exceeding limit: {days_exceeding_limit}\")\n",
    "print(f\"Total days: {total_days}\")\n",
    "print(f\"Percentage of days exceeding limit: {percentage_exceeding:.2f}%\")\n",
    "\n",
    "# Show which days exceeded the limit\n",
    "days_over_limit = alarms_per_day[alarms_per_day > limit]\n",
    "if len(days_over_limit) > 0:\n",
    "    print(f\"\\nDays that exceeded {limit} alarms:\")\n",
    "    print(days_over_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b7b04-5643-46ff-a1f9-ffc2f1c1a073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f261f5-d9a2-4b32-8097-ff43d781e50d",
   "metadata": {},
   "source": [
    "## Bad Actors Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e61a5af7-01f6-4973-8b87-67e5588edbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2025-01-01 00:00:00\n",
       "1     2025-01-01 00:00:00\n",
       "4     2025-01-01 00:00:00\n",
       "6     2025-01-01 00:00:00\n",
       "7     2025-01-01 00:00:00\n",
       "              ...        \n",
       "122   2025-01-01 00:10:00\n",
       "123   2025-01-01 00:10:00\n",
       "124   2025-01-01 00:10:00\n",
       "125   2025-01-01 00:10:00\n",
       "126   2025-01-01 00:10:00\n",
       "Name: Event Time, Length: 100, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = alarms_df['Event Time'].dt.floor('10min')\n",
    "var[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ff96ef3-759e-4925-ae27-d5856025500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_column = 'Source'\n",
    "# Group by 10-min interval and source, count alarms\n",
    "bad_actor_threshold = 10\n",
    "alarms_by_source_10min = alarms_df.groupby(['10Min', source_column]).size().reset_index(name='alarm_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41ce2fc5-1d21-48f2-b5c6-c457ea0900cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Min</th>\n",
       "      <th>Source</th>\n",
       "      <th>alarm_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>AIOR-704</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>DAILY RP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>EI1301B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>FIC1506A</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>FIC1506B</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145543</th>\n",
       "      <td>2025-03-17 10:40:00</td>\n",
       "      <td>TIC1203</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145544</th>\n",
       "      <td>2025-03-17 10:40:00</td>\n",
       "      <td>TIC1301B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145545</th>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>AI1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145546</th>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>AI_PH10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145547</th>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>TIC1301B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     10Min    Source  alarm_count\n",
       "0      2025-01-01 00:00:00  AIOR-704           10\n",
       "1      2025-01-01 00:00:00  DAILY RP            2\n",
       "2      2025-01-01 00:00:00   EI1301B            2\n",
       "3      2025-01-01 00:00:00  FIC1506A           17\n",
       "4      2025-01-01 00:00:00  FIC1506B           10\n",
       "...                    ...       ...          ...\n",
       "145543 2025-03-17 10:40:00   TIC1203           13\n",
       "145544 2025-03-17 10:40:00  TIC1301B            2\n",
       "145545 2025-03-17 10:50:00    AI1301            1\n",
       "145546 2025-03-17 10:50:00   AI_PH10            1\n",
       "145547 2025-03-17 10:50:00  TIC1301B            1\n",
       "\n",
       "[145548 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms_by_source_10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5a6fdf9-0f4a-4072-aee2-5b91a356eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify bad actors (10 or more alarms from same source in 10 min)\n",
    "bad_actors = alarms_by_source_10min[alarms_by_source_10min['alarm_count'] >= bad_actor_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2076067f-e231-4b28-af97-96478feef4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Min</th>\n",
       "      <th>Source</th>\n",
       "      <th>alarm_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>AIOR-704</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>FIC1506A</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>FIC1506B</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-01-01 00:10:00</td>\n",
       "      <td>FIC1501</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2025-01-01 00:20:00</td>\n",
       "      <td>EVENT_SCM1A</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145451</th>\n",
       "      <td>2025-03-17 09:20:00</td>\n",
       "      <td>OP_SUPER_A</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145483</th>\n",
       "      <td>2025-03-17 09:50:00</td>\n",
       "      <td>OP_SUPER_A</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145523</th>\n",
       "      <td>2025-03-17 10:30:00</td>\n",
       "      <td>$ACTIVITY_330413F2352AB609</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145529</th>\n",
       "      <td>2025-03-17 10:30:00</td>\n",
       "      <td>OP_NASH1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145543</th>\n",
       "      <td>2025-03-17 10:40:00</td>\n",
       "      <td>TIC1203</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13204 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     10Min                      Source  alarm_count\n",
       "0      2025-01-01 00:00:00                    AIOR-704           10\n",
       "3      2025-01-01 00:00:00                    FIC1506A           17\n",
       "4      2025-01-01 00:00:00                    FIC1506B           10\n",
       "20     2025-01-01 00:10:00                     FIC1501           10\n",
       "44     2025-01-01 00:20:00                 EVENT_SCM1A           16\n",
       "...                    ...                         ...          ...\n",
       "145451 2025-03-17 09:20:00                  OP_SUPER_A           28\n",
       "145483 2025-03-17 09:50:00                  OP_SUPER_A           10\n",
       "145523 2025-03-17 10:30:00  $ACTIVITY_330413F2352AB609          112\n",
       "145529 2025-03-17 10:30:00                    OP_NASH1           10\n",
       "145543 2025-03-17 10:40:00                     TIC1203           13\n",
       "\n",
       "[13204 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b277727c-8035-4e7f-9566-c8aa8baff305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\2456076691.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alarms_df['is_bad_actor'] = False\n"
     ]
    }
   ],
   "source": [
    "alarms_df['is_bad_actor'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67100fc3-41ef-4dca-9645-232ed0594440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\1924898867.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alarms_df['is_bad_actor'] = False\n"
     ]
    }
   ],
   "source": [
    "# Mark alarms in original dataframe that are from bad actors\n",
    "alarms_df['is_bad_actor'] = False\n",
    "for _, row in bad_actors.iterrows():\n",
    "    mask = (alarms_df['10Min'] == row['10Min']) & (alarms_df[source_column] == row[source_column])\n",
    "    alarms_df.loc[mask, 'is_bad_actor'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edb9832a-187d-4402-b40b-5b9ab4a16af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BAD ACTORS ANALYSIS ---\n",
      "Bad actor threshold: 10 alarms per source per 10 minutes\n",
      "Total alarms: 757264\n",
      "Alarms from bad actors: 438444\n",
      "Percentage of alarms from bad actors: 57.90%\n",
      "\n",
      "Number of bad actor incidents (source-time combinations): 13204\n",
      "Unique bad actor sources: 195\n",
      "\n",
      "Top 10 bad actor incidents:\n",
      "       Source               10Min  alarm_count\n",
      "14129  REPORT 2025-01-07 04:30:00         7790\n",
      "55687  REPORT 2025-01-29 09:00:00         6300\n",
      "55688  REPORT 2025-01-29 09:10:00         6300\n",
      "55693  REPORT 2025-01-29 09:20:00         6300\n",
      "14118  REPORT 2025-01-07 04:20:00         6000\n",
      "55701  REPORT 2025-01-29 09:30:00         5628\n",
      "14090  REPORT 2025-01-07 04:10:00         5292\n",
      "1433   REPORT 2025-01-01 15:10:00         3890\n",
      "19578  REPORT 2025-01-11 05:30:00         3466\n",
      "5337   REPORT 2025-01-03 04:10:00         3327\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "total_alarms = len(alarms_df)\n",
    "bad_actor_alarms = alarms_df['is_bad_actor'].sum()\n",
    "percentage_bad_actors = (bad_actor_alarms / total_alarms) * 100\n",
    "\n",
    "print(f\"\\n--- BAD ACTORS ANALYSIS ---\")\n",
    "print(f\"Bad actor threshold: {bad_actor_threshold} alarms per source per 10 minutes\")\n",
    "print(f\"Total alarms: {total_alarms}\")\n",
    "print(f\"Alarms from bad actors: {bad_actor_alarms}\")\n",
    "print(f\"Percentage of alarms from bad actors: {percentage_bad_actors:.2f}%\")\n",
    "print(f\"\\nNumber of bad actor incidents (source-time combinations): {len(bad_actors)}\")\n",
    "print(f\"Unique bad actor sources: {bad_actors[source_column].nunique()}\")\n",
    "\n",
    "# Show top bad actors\n",
    "if len(bad_actors) > 0:\n",
    "    top_bad_actors = bad_actors.nlargest(10, 'alarm_count')\n",
    "    print(f\"\\nTop 10 bad actor incidents:\")\n",
    "    print(top_bad_actors[[source_column, '10Min', 'alarm_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95069528-86c8-48dc-8ad4-727c46db54ef",
   "metadata": {},
   "source": [
    "# Bad Actor Analysis - Calculation Explanation\n",
    "\n",
    "## Overview\n",
    "This analysis identifies \"bad actors\" - sources that generate an excessive number of alarms in a short time period, which may indicate a malfunctioning system or misconfigured device rather than genuine issues.\n",
    "\n",
    "---\n",
    "\n",
    "## Definition: What is a Bad Actor?\n",
    "\n",
    "A **bad actor** is defined as:\n",
    "> Any source that generates **10 or more alarms within the same 10-minute interval**\n",
    "\n",
    "### Example:\n",
    "- **ServerA** generates 15 alarms between 2:30 PM and 2:40 PM → **Bad Actor** ✅\n",
    "- **ServerB** generates 8 alarms between 2:30 PM and 2:40 PM → **Not a Bad Actor** ❌\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Calculation Process\n",
    "\n",
    "### Step 1: Create 10-Minute Time Intervals\n",
    "Each alarm timestamp is rounded down to the nearest 10-minute interval.\n",
    "\n",
    "**Example:**\n",
    "| Original Timestamp | 10-Minute Interval |\n",
    "|-------------------|-------------------|\n",
    "| 2025-01-03 14:37:25 | 2025-01-03 14:30:00 |\n",
    "| 2025-01-03 14:42:10 | 2025-01-03 14:40:00 |\n",
    "| 2025-01-03 14:38:45 | 2025-01-03 14:30:00 |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Group and Count Alarms\n",
    "Count how many alarms each source generated in each 10-minute interval.\n",
    "\n",
    "**Example Result:**\n",
    "| 10-Minute Interval | Source | Alarm Count |\n",
    "|-------------------|---------|-------------|\n",
    "| 2025-01-03 14:30 | ServerA | 15 |\n",
    "| 2025-01-03 14:30 | ServerB | 3 |\n",
    "| 2025-01-03 14:40 | ServerA | 8 |\n",
    "| 2025-01-03 14:40 | ServerC | 12 |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Identify Bad Actor Incidents\n",
    "Filter for combinations where **Alarm Count ≥ 10**\n",
    "\n",
    "**Bad Actor Incidents:**\n",
    "| 10-Minute Interval | Source | Alarm Count |\n",
    "|-------------------|---------|-------------|\n",
    "| 2025-01-03 14:30 | ServerA | 15 | ← Bad Actor\n",
    "| 2025-01-03 14:40 | ServerC | 12 | ← Bad Actor\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Mark All Alarms from Bad Actors\n",
    "Go back to the original alarm list and mark every alarm that belongs to a bad actor incident.\n",
    "\n",
    "**Example:**\n",
    "- All 15 alarms from ServerA between 14:30-14:40 are marked as \"bad actor alarms\"\n",
    "- All 12 alarms from ServerC between 14:40-14:50 are marked as \"bad actor alarms\"\n",
    "- The 3 alarms from ServerB remain unmarked (not a bad actor)\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Calculate Percentage\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "Percentage of Bad Actor Alarms = (Number of Bad Actor Alarms / Total Number of Alarms) × 100\n",
    "```\n",
    "\n",
    "**Example Calculation:**\n",
    "- Total Alarms: 1,000\n",
    "- Bad Actor Alarms: 250\n",
    "- Percentage: (250 / 1,000) × 100 = **25%**\n",
    "\n",
    "This means **25% of all alarms** were caused by bad actors (sources generating excessive alarms).\n",
    "\n",
    "---\n",
    "\n",
    "## Key Metrics Reported\n",
    "\n",
    "### 1. **Total Alarms**\n",
    "The complete count of all alarms in the dataset (where Action column is blank/NaN).\n",
    "\n",
    "### 2. **Alarms from Bad Actors**\n",
    "The count of alarms that belong to bad actor incidents (10+ alarms from same source in 10 minutes).\n",
    "\n",
    "### 3. **Percentage of Alarms from Bad Actors**\n",
    "The proportion of total alarms caused by bad actors.\n",
    "\n",
    "### 4. **Number of Bad Actor Incidents**\n",
    "Count of unique (Source + 10-minute interval) combinations that exceeded the threshold.\n",
    "- Example: ServerA at 14:30, ServerA at 15:20, ServerB at 16:00 = 3 incidents\n",
    "\n",
    "### 5. **Unique Bad Actor Sources**\n",
    "Count of distinct sources that acted as bad actors at least once.\n",
    "- Example: If ServerA appears in 5 incidents and ServerB in 2 incidents, there are **2 unique bad actor sources**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e7841-26e8-4c4b-b0f5-9cfe3ac11229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Bad Actors Analysis ---\n",
    "# alarms_df['10Min'] = alarms_df['Event Time'].dt.floor('10min')\n",
    "# source_column = 'Source'\n",
    "# # Group by 10-min interval and source, count alarms\n",
    "# bad_actor_threshold = 10\n",
    "# alarms_by_source_10min = alarms_df.groupby(['10Min', source_column]).size().reset_index(name='alarm_count')\n",
    "\n",
    "# # Identify bad actors (10 or more alarms from same source in 10 min)\n",
    "# bad_actors = alarms_by_source_10min[alarms_by_source_10min['alarm_count'] >= bad_actor_threshold]\n",
    "\n",
    "# # Mark alarms in original dataframe that are from bad actors\n",
    "# alarms_df['is_bad_actor'] = False\n",
    "# for _, row in bad_actors.iterrows():\n",
    "#     mask = (alarms_df['10Min'] == row['10Min']) & (alarms_df[source_column] == row[source_column])\n",
    "#     alarms_df.loc[mask, 'is_bad_actor'] = True\n",
    "\n",
    "# # Calculate statistics\n",
    "# total_alarms = len(alarms_df)\n",
    "# bad_actor_alarms = alarms_df['is_bad_actor'].sum()\n",
    "# percentage_bad_actors = (bad_actor_alarms / total_alarms) * 100\n",
    "\n",
    "# print(f\"\\n--- BAD ACTORS ANALYSIS ---\")\n",
    "# print(f\"Bad actor threshold: {bad_actor_threshold} alarms per source per 10 minutes\")\n",
    "# print(f\"Total alarms: {total_alarms}\")\n",
    "# print(f\"Alarms from bad actors: {bad_actor_alarms}\")\n",
    "# print(f\"Percentage of alarms from bad actors: {percentage_bad_actors:.2f}%\")\n",
    "# print(f\"\\nNumber of bad actor incidents (source-time combinations): {len(bad_actors)}\")\n",
    "# print(f\"Unique bad actor sources: {bad_actors[source_column].nunique()}\")\n",
    "\n",
    "# # Show top bad actors\n",
    "# if len(bad_actors) > 0:\n",
    "#     top_bad_actors = bad_actors.nlargest(10, 'alarm_count')\n",
    "#     print(f\"\\nTop 10 bad actor incidents:\")\n",
    "#     print(top_bad_actors[[source_column, '10Min', 'alarm_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed064ab5-5e63-4da9-abd0-a98069f34b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>Location Tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Action</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Date</th>\n",
       "      <th>10Min</th>\n",
       "      <th>is_bad_actor</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>DAILY RP</td>\n",
       "      <td>PERIODIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>Report Periodic Request</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 00:00:03</td>\n",
       "      <td>1600</td>\n",
       "      <td>PI1601</td>\n",
       "      <td>PVLOLO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>HE1601 OUTLET</td>\n",
       "      <td>0.239591</td>\n",
       "      <td>kg/cm2G</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 00:00:07</td>\n",
       "      <td>1200</td>\n",
       "      <td>TIC1203</td>\n",
       "      <td>PVHIHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H 00</td>\n",
       "      <td>HE1203 D/S TEMP</td>\n",
       "      <td>88.7875</td>\n",
       "      <td>C</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-01 00:00:14</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>File Replication</td>\n",
       "      <td>REPLICATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>Filerep #14 replicating.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-01 00:00:18</td>\n",
       "      <td>1600</td>\n",
       "      <td>PNEUMOIS</td>\n",
       "      <td>Start</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J 00</td>\n",
       "      <td>SCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903347</th>\n",
       "      <td>2025-03-17 10:55:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-03-17 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903349</th>\n",
       "      <td>2025-03-17 10:55:00</td>\n",
       "      <td>1300</td>\n",
       "      <td>AI1301</td>\n",
       "      <td>PVLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L 00</td>\n",
       "      <td>VE1306 INLET</td>\n",
       "      <td>5.99933</td>\n",
       "      <td>ph</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-03-17 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903351</th>\n",
       "      <td>2025-03-17 10:55:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-03-17 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903352</th>\n",
       "      <td>2025-03-17 10:56:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-03-17 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903353</th>\n",
       "      <td>2025-03-17 10:56:00</td>\n",
       "      <td>SERVER_PVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV export in progress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025-03-17 10:50:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-03-17 10:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757264 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Event Time Location Tag            Source    Condition Action  \\\n",
       "0      2025-01-01 00:00:00   SERVER_PVC          DAILY RP     PERIODIC    NaN   \n",
       "1      2025-01-01 00:00:03         1600            PI1601       PVLOLO    NaN   \n",
       "4      2025-01-01 00:00:07         1200           TIC1203       PVHIHI    NaN   \n",
       "6      2025-01-01 00:00:14   SERVER_PVC  File Replication  REPLICATION    NaN   \n",
       "7      2025-01-01 00:00:18         1600          PNEUMOIS        Start    NaN   \n",
       "...                    ...          ...               ...          ...    ...   \n",
       "903347 2025-03-17 10:55:00   SERVER_PVC               NaN       Demand    NaN   \n",
       "903349 2025-03-17 10:55:00         1300            AI1301        PVLOW    NaN   \n",
       "903351 2025-03-17 10:55:00   SERVER_PVC               NaN       Demand    NaN   \n",
       "903352 2025-03-17 10:56:00   SERVER_PVC               NaN       Demand    NaN   \n",
       "903353 2025-03-17 10:56:00   SERVER_PVC               NaN       Demand    NaN   \n",
       "\n",
       "       Priority                Description     Value    Units        Date  \\\n",
       "0          J 00    Report Periodic Request        12      NaN  2025-01-01   \n",
       "1          J 00              HE1601 OUTLET  0.239591  kg/cm2G  2025-01-01   \n",
       "4          H 00            HE1203 D/S TEMP   88.7875        C  2025-01-01   \n",
       "6          J 00   Filerep #14 replicating.       NaN      NaN  2025-01-01   \n",
       "7          J 00                        SCM       NaN      NaN  2025-01-01   \n",
       "...         ...                        ...       ...      ...         ...   \n",
       "903347      NaN  CSV export in progress...       NaN      NaN  2025-03-17   \n",
       "903349     L 00               VE1306 INLET   5.99933       ph  2025-03-17   \n",
       "903351      NaN  CSV export in progress...       NaN      NaN  2025-03-17   \n",
       "903352      NaN  CSV export in progress...       NaN      NaN  2025-03-17   \n",
       "903353      NaN  CSV export in progress...       NaN      NaN  2025-03-17   \n",
       "\n",
       "                     10Min  is_bad_actor                Hour  \n",
       "0      2025-01-01 00:00:00         False 2025-01-01 00:00:00  \n",
       "1      2025-01-01 00:00:00         False 2025-01-01 00:00:00  \n",
       "4      2025-01-01 00:00:00         False 2025-01-01 00:00:00  \n",
       "6      2025-01-01 00:00:00         False 2025-01-01 00:00:00  \n",
       "7      2025-01-01 00:00:00         False 2025-01-01 00:00:00  \n",
       "...                    ...           ...                 ...  \n",
       "903347 2025-03-17 10:50:00         False 2025-03-17 10:00:00  \n",
       "903349 2025-03-17 10:50:00         False 2025-03-17 10:00:00  \n",
       "903351 2025-03-17 10:50:00         False 2025-03-17 10:00:00  \n",
       "903352 2025-03-17 10:50:00         False 2025-03-17 10:00:00  \n",
       "903353 2025-03-17 10:50:00         False 2025-03-17 10:00:00  \n",
       "\n",
       "[757264 rows x 13 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f62f9ca9-eee5-4274-ab85-5c5f4c399dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\2067315980.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  alarms_df['Hour'] = alarms_df[event_date_column].dt.floor('H')\n",
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\2067315980.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alarms_df['Hour'] = alarms_df[event_date_column].dt.floor('H')\n",
      "C:\\Users\\hmaba\\AppData\\Local\\Temp\\ipykernel_7180\\2067315980.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alarms_df['10Min'] = alarms_df[event_date_column].dt.floor('10min')\n"
     ]
    }
   ],
   "source": [
    "# Create the Hour and 10Min columns first\n",
    "event_date_column = 'Event Time'  # Replace with your actual datetime column name\n",
    "\n",
    "alarms_df['Hour'] = alarms_df[event_date_column].dt.floor('H')\n",
    "alarms_df['10Min'] = alarms_df[event_date_column].dt.floor('10min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014cff53-5694-4fb8-b05f-3718d356ae4e",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60abe22c-f0cb-440e-aee7-65749fa97d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Sources: 1227\n"
     ]
    }
   ],
   "source": [
    "alarms_df_unique_count = alarms_df['Source'].nunique()\n",
    "print(f\"Number of unique Sources: {alarms_df_unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c25f6df9-c381-455c-ae6c-42297b5a2a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Alarms: 757264\n"
     ]
    }
   ],
   "source": [
    "alarms_df_alarm_count = alarms_df['Action'].isna().sum()\n",
    "print(f\"Number of Unique Alarms: {alarms_df_alarm_count}\")\n",
    "\n",
    "\n",
    "# An Alarm is in active state till no action perform on it and it is considered as 1 alarm till no action performing on it \n",
    "# If no one perform any action on an single source alarm for long duration then it will be considered as stale alarm\n",
    "# And if an alarm from same source occurs repeatedly in short duration with the actions performed on it by operator as well\n",
    "# then it should be considered as Chattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "167b0532-0e0a-41f4-b354-e9ea596689ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULT ---\n",
      "Average Alarms per Day: 10096.85\n",
      "\n",
      "Total unique days: 75\n",
      "Max alarms in a day: 30374\n",
      "Min alarms in a day: 738\n",
      "Date range: 2025-01-01 to 2025-03-17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Count alarms per day\n",
    "alarms_per_day = alarms_df.groupby('Date').size()\n",
    "\n",
    "# print(f\"\\nAlarms per day:\\n{alarms_per_day}\")\n",
    "\n",
    "# Calculate average alarms per day\n",
    "average_alarms_per_day = alarms_per_day.mean()\n",
    "\n",
    "print(f\"\\n--- RESULT ---\")\n",
    "print(f\"Average Alarms per Day: {average_alarms_per_day:.2f}\")\n",
    "\n",
    "# Additional statistics\n",
    "print(f\"\\nTotal unique days: {len(alarms_per_day)}\")\n",
    "print(f\"Max alarms in a day: {alarms_per_day.max()}\")\n",
    "print(f\"Min alarms in a day: {alarms_per_day.min()}\")\n",
    "print(f\"Date range: {alarms_df['Date'].min()} to {alarms_df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "161b978c-1298-4052-95c3-732f6f4b7550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVERAGE ALARMS PER HOUR ---\n",
      "Average Alarms per Hour: 424.48\n",
      "Total unique hours: 1784\n",
      "Max alarms in an hour: 24763\n",
      "Min alarms in an hour: 1\n",
      "\n",
      "--- AVERAGE ALARMS PER 10 MINUTES ---\n",
      "Average Alarms per 10 Minutes: 72.95\n",
      "Total unique 10-min intervals: 10380\n",
      "Max alarms in a 10-min interval: 7805\n",
      "Min alarms in a 10-min interval: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Average Alarms per Hour ---\n",
    "alarms_per_hour = alarms_df.groupby('Hour').size()\n",
    "average_alarms_per_hour = alarms_per_hour.mean()\n",
    "print(f\"\\n--- AVERAGE ALARMS PER HOUR ---\")\n",
    "print(f\"Average Alarms per Hour: {average_alarms_per_hour:.2f}\")\n",
    "print(f\"Total unique hours: {len(alarms_per_hour)}\")\n",
    "print(f\"Max alarms in an hour: {alarms_per_hour.max()}\")\n",
    "print(f\"Min alarms in an hour: {alarms_per_hour.min()}\")\n",
    "\n",
    "# --- Average Alarms per 10 Minutes ---\n",
    "alarms_per_10min = alarms_df.groupby('10Min').size()\n",
    "average_alarms_per_10min = alarms_per_10min.mean()\n",
    "print(f\"\\n--- AVERAGE ALARMS PER 10 MINUTES ---\")\n",
    "print(f\"Average Alarms per 10 Minutes: {average_alarms_per_10min:.2f}\")\n",
    "print(f\"Total unique 10-min intervals: {len(alarms_per_10min)}\")\n",
    "print(f\"Max alarms in a 10-min interval: {alarms_per_10min.max()}\")\n",
    "print(f\"Min alarms in a 10-min interval: {alarms_per_10min.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76d23b50-611c-4a66-a233-c4adf6964ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BAD ACTORS ANALYSIS ---\n",
      "Bad actor threshold: 10 alarms per source per 10 minutes\n",
      "Total alarms: 757264\n",
      "Alarms from bad actors: 438444\n",
      "Percentage of alarms from bad actors: 57.90%\n",
      "\n",
      "Number of bad actor incidents (source-time combinations): 13204\n",
      "Unique bad actor sources: 195\n",
      "\n",
      "Top 10 bad actor incidents:\n",
      "       Source               10Min  alarm_count\n",
      "14129  REPORT 2025-01-07 04:30:00         7790\n",
      "55687  REPORT 2025-01-29 09:00:00         6300\n",
      "55688  REPORT 2025-01-29 09:10:00         6300\n",
      "55693  REPORT 2025-01-29 09:20:00         6300\n",
      "14118  REPORT 2025-01-07 04:20:00         6000\n",
      "55701  REPORT 2025-01-29 09:30:00         5628\n",
      "14090  REPORT 2025-01-07 04:10:00         5292\n",
      "1433   REPORT 2025-01-01 15:10:00         3890\n",
      "19578  REPORT 2025-01-11 05:30:00         3466\n",
      "5337   REPORT 2025-01-03 04:10:00         3327\n"
     ]
    }
   ],
   "source": [
    "# with max alarm count in a flood a source could be considered as bad actor\n",
    "# unhealthy source if an alarm occurs >= 10 in 10 minutes duration\n",
    "# If multiple sources are in active state or multiple alarms occurs from multiple sources in 10 min window or more then it would be considered as Flood\n",
    "\n",
    "# Calculate statistics\n",
    "total_alarms = len(alarms_df)\n",
    "bad_actor_alarms = alarms_df['is_bad_actor'].sum()\n",
    "percentage_bad_actors = (bad_actor_alarms / total_alarms) * 100\n",
    "\n",
    "print(f\"\\n--- BAD ACTORS ANALYSIS ---\")\n",
    "print(f\"Bad actor threshold: {bad_actor_threshold} alarms per source per 10 minutes\")\n",
    "print(f\"Total alarms: {total_alarms}\")\n",
    "print(f\"Alarms from bad actors: {bad_actor_alarms}\")\n",
    "print(f\"Percentage of alarms from bad actors: {percentage_bad_actors:.2f}%\")\n",
    "print(f\"\\nNumber of bad actor incidents (source-time combinations): {len(bad_actors)}\")\n",
    "print(f\"Unique bad actor sources: {bad_actors[source_column].nunique()}\")\n",
    "\n",
    "# Show top bad actors\n",
    "if len(bad_actors) > 0:\n",
    "    top_bad_actors = bad_actors.nlargest(10, 'alarm_count')\n",
    "    print(f\"\\nTop 10 bad actor incidents:\")\n",
    "    print(top_bad_actors[[source_column, '10Min', 'alarm_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c817557-4ccb-4ea6-b312-89fa70c05834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DAYS EXCEEDING LIMIT ---\n",
      "Limit: 288 alarms per day\n",
      "Days exceeding limit: 75\n",
      "Total days: 75\n",
      "Percentage of days exceeding limit: 100.00%\n",
      "\n",
      "Days that exceeded 288 alarms:\n",
      "Date\n",
      "2025-01-01    18482\n",
      "2025-01-02    13287\n",
      "2025-01-03    16523\n",
      "2025-01-04    13248\n",
      "2025-01-05    11355\n",
      "              ...  \n",
      "2025-03-13     3866\n",
      "2025-03-14    11363\n",
      "2025-03-15    12078\n",
      "2025-03-16    10719\n",
      "2025-03-17     5171\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate % of days exceeding 288 alarms ---\n",
    "\n",
    "limit = 288\n",
    "# Count alarms per day\n",
    "alarms_per_day = alarms_df.groupby('Date').size()\n",
    "# Count days where alarms exceed the limit\n",
    "days_exceeding_limit = (alarms_per_day > limit).sum()\n",
    "total_days = len(alarms_per_day)\n",
    "\n",
    "# Calculate percentage\n",
    "percentage_exceeding = (days_exceeding_limit / total_days) * 100\n",
    "\n",
    "print(f\"\\n--- DAYS EXCEEDING LIMIT ---\")\n",
    "print(f\"Limit: {limit} alarms per day\")\n",
    "print(f\"Days exceeding limit: {days_exceeding_limit}\")\n",
    "print(f\"Total days: {total_days}\")\n",
    "print(f\"Percentage of days exceeding limit: {percentage_exceeding:.2f}%\")\n",
    "\n",
    "# Show which days exceeded the limit\n",
    "days_over_limit = alarms_per_day[alarms_per_day > limit]\n",
    "if len(days_over_limit) > 0:\n",
    "    print(f\"\\nDays that exceeded {limit} alarms:\")\n",
    "    print(days_over_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad9d82-79cf-44c8-9b56-05047b758030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
